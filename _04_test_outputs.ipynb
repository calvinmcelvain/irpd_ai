{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast \n",
    "import pandas as pd\n",
    "\n",
    "# Working Dir.\n",
    "os.chdir('/Users/fogellmcmuffin/Documents/ra/team_discussions/AI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Functions ##\n",
    "###############\n",
    "\n",
    "def extract_dict_from_file(file_path):  # Extracting info from GPT response text files\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:    # Opening response file\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    text = ''.join(lines)\n",
    "    \n",
    "    # Extracting dictionary\n",
    "    start = text.find('{')\n",
    "    end = text.find('}') + 1\n",
    "    dict_text = text[start:end]\n",
    "    \n",
    "    cat_dict = ast.literal_eval(dict_text) # Turning dictionary string into python dictionary\n",
    "    \n",
    "    for i in cat_dict['assigned_categories']:  # Making a binary key for each assigned category\n",
    "        cat_dict[i] = 1\n",
    "    \n",
    "    # Extracting GPT reasoning\n",
    "    start_keyword = \"Step-by-step Reasoning: \"\n",
    "    end_keyword = \"Python Dictionary:\"\n",
    "\n",
    "    start_index = text.find(start_keyword) + len(start_keyword)\n",
    "    end_index = text.find(end_keyword)\n",
    "    reasoning = text[start_index:end_index].strip()\n",
    "    \n",
    "    data_dict = {}\n",
    "    data_dict['gpt_reasoning'] = reasoning\n",
    "    \n",
    "    for key, value in cat_dict.items(): # Making sure gpt_reasoning is the first key\n",
    "        data_dict[key] = value\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def response_df(response_dir, test_df):  # Turning dictionary list into GPT coded dataframe\n",
    "    resp_list = []\n",
    "    \n",
    "    for file in os.listdir(response_dir):\n",
    "        file_path = os.path.join(response_dir, file)\n",
    "        reponse_dict = extract_dict_from_file(file_path)\n",
    "        resp_list.append(reponse_dict)\n",
    "    \n",
    "    df = pd.DataFrame.from_records(resp_list)\n",
    "    df = df.drop(['assigned_categories'], axis=1)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    df = pd.merge(test_df, df, on='window_number', how='outer')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def ucoop_udef_rename(df, prefix):  # Function to add ucoop or udef prefix to created category columns\n",
    "    remove_columns = ['summary', 'unilateral_cooperation', 'window_number', 'gpt_reasoning', 'a', 'b', 'c', 'd', 'e']\n",
    "    df_dropped = df.drop(columns=remove_columns)\n",
    "    category_columns = df_dropped.columns.to_list()\n",
    "    \n",
    "    rename_dict = {col: f'{prefix}_{col}' for col in category_columns}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## GPT Coded DataFrame ##\n",
    "#########################\n",
    "\n",
    "treatment = 'noise' \n",
    "\n",
    "ucoop_test_data = pd.read_csv(f'test_data/RAsum_{treatment}_ucoop.csv')\n",
    "udef_test_data = pd.read_csv(f'test_data/RAsum_{treatment}_udef.csv')\n",
    "ucoop_test_data = ucoop_test_data[:20]\n",
    "ucoop_test_data['window_number'] = ucoop_test_data['window_number'].astype(int)\n",
    "ucoop_test_data['unilateral_cooperation'] = 1\n",
    "udef_test_data = udef_test_data[:20]\n",
    "udef_test_data['window_number'] = udef_test_data['window_number'].astype(int)\n",
    "udef_test_data['unilateral_cooperation'] = 0\n",
    "\n",
    "test = 'test_10'\n",
    "ucoop_response_dir = f'output/{test}/stage_2_ucoop/responses/'\n",
    "udef_response_dir = f'output/{test}/stage_2_udef/responses/'\n",
    "\n",
    "ucoop_df = response_df(ucoop_response_dir, ucoop_test_data)\n",
    "ucoop_df = ucoop_udef_rename(ucoop_df, 'ucoop')\n",
    "\n",
    "udef_df = response_df(udef_response_dir, udef_test_data)\n",
    "udef_df = ucoop_udef_rename(udef_df, 'udef')\n",
    "GPT_df = pd.concat([ucoop_df, udef_df], ignore_index=True, sort=False)\n",
    "GPT_df = GPT_df.fillna(0)\n",
    "GPT_df.to_csv(f'output/{test}/t{test[5:]}_final_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
