{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# Working Dir.\n",
    "os.chdir('/Users/fogellmcmuffin/Documents/ra/team_discussions/AI/')\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-BBrbzGnsFwklndehaTC1T3BlbkFJEGPQt0QfhWkwp9ePuxaK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## Model Settings ##\n",
    "####################\n",
    "\n",
    "# Calling for OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    organization='org-WLFAmqjnKmywM0wd6loMyGJq',    # RA_WORK\n",
    "    project='proj_vOr6WeeCFk5IjZLCdksFLWUd',    # IRPD_CODING\n",
    ")\n",
    "\n",
    "# Model Settings\n",
    "MODEL = 'gpt-4o-2024-05-13'\n",
    "TEMPERATURE = 0\n",
    "MAX_TOKENS = 1300\n",
    "TOP_P = 1\n",
    "FREQUENCY_PENALTY = 0\n",
    "PRESENCE_PENALTY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## Prompt Functions ##\n",
    "######################\n",
    "\n",
    "def file_to_string(file_path):  # File read-to-string functions\n",
    "  with open(file_path, 'r') as file:\n",
    "    k = file.read()\n",
    "  return str(k)\n",
    "\n",
    "\n",
    "def write_file(file_path, file_write):  # File write function\n",
    "  with open(file_path, 'w') as file:\n",
    "    file.write(file_write)     \n",
    "\n",
    "\n",
    "def test_info(test, data_name):  # Function to get test info\n",
    "  info = str(\n",
    "    'ChatGPT Model Information:' + '\\n' +\n",
    "    'format: OpenAI API' + '\\n' +\n",
    "    'model: ' + str(MODEL) + '\\n' +\n",
    "    'temperature: ' + str(TEMPERATURE) + '\\n' +\n",
    "    'max tokens: ' + str(MAX_TOKENS) + '\\n' +\n",
    "    'top p: ' + str(TOP_P) + '\\n' +\n",
    "    'frequency penalty: ' + str(FREQUENCY_PENALTY) + '\\n' +\n",
    "    'presence penalty: ' + str(PRESENCE_PENALTY) + '\\n\\n' +\n",
    "    'Test Information:' + '\\n' + \n",
    "    'test: ' + test + '\\n' +\n",
    "    'data: ' + data_name + '\\n' +\n",
    "    'date: ' + str(date.today()) + '\\n'\n",
    "  )\n",
    "  return info\n",
    "\n",
    "\n",
    "def GPT_response(sys, user):  # Simple GPT response function\n",
    "  # Requesting chat completion\n",
    "  response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    top_p=TOP_P,\n",
    "    frequency_penalty=FREQUENCY_PENALTY,\n",
    "    presence_penalty=PRESENCE_PENALTY,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": str(sys)},\n",
    "      {\"role\": \"user\", \"content\": str(user)}\n",
    "    ]\n",
    "  )\n",
    "  output = response.choices[0].message.content  # GPT response var\n",
    "  \n",
    "  return output\n",
    "\n",
    "\n",
    "def test_GPT(sys_path, user_path, df_name):  # Function for non-official tests\n",
    "  # utf-8 encoding prompts\n",
    "  sys = file_to_string(sys_path)\n",
    "  user = file_to_string(user_path)\n",
    "  \n",
    "  # Generating new folder for subtest\n",
    "  dir_numbers = [int(d) for d in os.listdir('output/_subtests/') if d.isdigit()]\n",
    "  max_number = max(dir_numbers) # Getting max number in subtest directory\n",
    "  unique_id = max_number + 1\n",
    "  test_dir = os.path.join('output/_subtests/', str(unique_id))\n",
    "  os.makedirs(test_dir, exist_ok=False)  # Attempt to create the directory\n",
    "  info = test_info(f\"Sub-test {unique_id}\", df_name)  # Getting test info\n",
    "  info_path = os.path.join(test_dir, f'{unique_id}__subtest_info.txt')\n",
    "  write_file(info_path, info)\n",
    "  \n",
    "  output = GPT_response(sys, user) # Requesting chat completion\n",
    "  \n",
    "  # Creating paths for prompts & GPT response\n",
    "  sys_prmpt_path = os.path.join(test_dir, f'{unique_id}_sys_prmpt.txt')\n",
    "  user_prmpt_path = os.path.join(test_dir, f'{unique_id}_user_prmpt.txt')\n",
    "  response_path = os.path.join(test_dir, f'{unique_id}_response.txt')\n",
    "  \n",
    "  # Writing .txt files for prompts & GPT response\n",
    "  write_file(sys_prmpt_path, str(sys))\n",
    "  write_file(user_prmpt_path, str(user))\n",
    "  write_file(response_path, str(output))\n",
    "  \n",
    "  return print(f'Sub-test {unique_id} complete')\n",
    "\n",
    "\n",
    "def stage_1_output(treatment, test):  # Stage 1 function: Creating categories\n",
    "  # utf-8 encoding prompts\n",
    "  sys_ucoop = file_to_string(f'code/prompts/ucoop/{treatment}/sys_1_{treatment}_ucoop.md')\n",
    "  sys_udef = file_to_string(f'code/prompts/udef/{treatment}/sys_1_{treatment}_udef.md')\n",
    "  user_ucoop = file_to_string(f'code/prompts/ucoop/{treatment}/user_1_{treatment}_ucoop.md')\n",
    "  user_udef = file_to_string(f'code/prompts/udef/{treatment}/user_1_{treatment}_udef.md')\n",
    "  window_prompts = [['ucoop', sys_ucoop, user_ucoop], ['udef', sys_udef, user_udef]]\n",
    "  \n",
    "  # Making test directory\n",
    "  test_dir = os.path.join('output/', test)\n",
    "  os.makedirs(test_dir, exist_ok=True)\n",
    "  \n",
    "  # Test info\n",
    "  info = test_info(f\"Test {test[5:]}\", f'RAsum_{treatment}_ucoop.csv & RAsum_{treatment}_udef.csv')\n",
    "  info_path = os.path.join(test_dir, f't{test[5:]}_test_info.txt')\n",
    "  write_file(info_path, info)\n",
    "  \n",
    "  # Creating stage 1 windows\n",
    "  for i in window_prompts:\n",
    "    stage_dir = os.path.join(test_dir, f'stage_1_{i[0]}')\n",
    "    os.makedirs(stage_dir, exist_ok=False)  # Stage directory\n",
    "    \n",
    "    # GPT request output\n",
    "    output = GPT_response(i[1], i[2])\n",
    "    \n",
    "    # Creating paths for prompts & GPT response\n",
    "    sys_prmpt_path = os.path.join(stage_dir, f't{test[5:]}_stg_1_{i[0]}_sys_prmpt.txt')\n",
    "    user_prmpt_path = os.path.join(stage_dir, f't{test[5:]}_stg_1_{i[0]}_user_prmpt.txt')\n",
    "    response_path = os.path.join(stage_dir, f't{test[5:]}_stg_1_{i[0]}_response.txt')\n",
    "    \n",
    "    # Writing .txt files for prompts & GPT response\n",
    "    write_file(sys_prmpt_path, i[1])\n",
    "    write_file(user_prmpt_path, i[2])\n",
    "    write_file(response_path, str(output))\n",
    "  \n",
    "  return print(\"Stage 1 Complete\")\n",
    "\n",
    "\n",
    "def stage_1r_output(treatment, test):  # Stage 1 category refinement function\n",
    "  # utf-8 encoding prompts\n",
    "  sys_ucoop = file_to_string(f'code/prompts/ucoop/{treatment}/sys_1r_{treatment}_ucoop.md')\n",
    "  sys_udef = file_to_string(f'code/prompts/udef/{treatment}/sys_1r_{treatment}_udef.md')\n",
    "  user_ucoop = file_to_string(f'code/prompts/ucoop/{treatment}/user_1r_{treatment}_ucoop.md')\n",
    "  user_udef = file_to_string(f'code/prompts/udef/{treatment}/user_1r_{treatment}_udef.md')\n",
    "  window_prompts = [['ucoop', sys_ucoop, user_ucoop], ['udef', sys_udef, user_udef]]\n",
    "  \n",
    "  test_dir = f'output/{test}/'    # Test directory\n",
    "  \n",
    "  for i in window_prompts:\n",
    "    stage_dir = os.path.join(test_dir, f'stage_1r_{i[0]}')\n",
    "    os.makedirs(stage_dir, exist_ok=False)  # Stage directory\n",
    "    \n",
    "    # GPT request output\n",
    "    output = GPT_response(i[1], i[2])\n",
    "    \n",
    "    # Creating paths for prompts & GPT response\n",
    "    sys_prmpt_path = os.path.join(stage_dir, f't{test[5:]}_stg_1r_{i[0]}_sys_prmpt.txt')\n",
    "    user_prmpt_path = os.path.join(stage_dir, f't{test[5:]}_stg_1r_{i[0]}_user_prmpt.txt')\n",
    "    response_path = os.path.join(stage_dir, f't{test[5:]}_stg_1r_{i[0]}_response.txt')\n",
    "    \n",
    "    # Writing .txt files for prompts & GPT response\n",
    "    write_file(sys_prmpt_path, i[1])\n",
    "    write_file(user_prmpt_path, i[2])\n",
    "    write_file(response_path, str(output))\n",
    "  \n",
    "  return print(\"Stage 1 Refinement Complete\")\n",
    "\n",
    "\n",
    "def stage_2_output(treatment, test, df_ucoop, df_udef): # Stage 2 function: Assigning categories to individual summaries (recursive)\n",
    "  # utf-8 encoding system prompt\n",
    "  sys_ucoop = file_to_string(f'code/prompts/ucoop/{treatment}/sys_2_{treatment}_ucoop.md')\n",
    "  sys_udef = file_to_string(f'code/prompts/udef/{treatment}/sys_2_{treatment}_udef.md')\n",
    "  window_prompts = [['ucoop', sys_ucoop, df_ucoop], ['udef', sys_udef, df_udef]]\n",
    "  \n",
    "  test_dir = f'output/{test}/'    # Test directory\n",
    "  \n",
    "  for i in window_prompts:\n",
    "    stage_dir = os.path.join(test_dir, f'stage_2_{i[0]}')\n",
    "    os.makedirs(stage_dir, exist_ok=False)  # Stage directory\n",
    "    \n",
    "    # Writing .txt system prompt (the same for every request)\n",
    "    sys = i[1]    # System prompt for ucoop or udef data\n",
    "    sys_prmpt_path = os.path.join(stage_dir, f't{test[5:]}_stg_2_{i[0]}_sys_prmpt.txt')\n",
    "    write_file(sys_prmpt_path, sys)\n",
    "    \n",
    "    # Prompt & Response paths\n",
    "    prompt_path = os.path.join(stage_dir, 'prompts')\n",
    "    response_path = os.path.join(stage_dir, 'responses')\n",
    "    os.makedirs(prompt_path, exist_ok=True)\n",
    "    os.makedirs(response_path, exist_ok=True)\n",
    "    \n",
    "    # Requesting chat completion for each row\n",
    "    df = i[2]   # Test data for ucoop or udef data\n",
    "    for k in range(len(df)):\n",
    "      row = df.iloc[k].to_dict()  # Creating a dictionary for each indv. row\n",
    "      \n",
    "      output = GPT_response(sys, str(row))  # GPT request output\n",
    "      \n",
    "      # Creating paths for prompts & GPT responses using window_numbers\n",
    "      window_number = row['window_number']\n",
    "      user_prmpt_path = os.path.join(prompt_path, f't{test[5:]}_{window_number}_user_prmpt.txt')\n",
    "      output_path = os.path.join(response_path, f't{test[5:]}_{window_number}_response.txt')\n",
    "      \n",
    "      # Writing .txt files for prompts & GPT response\n",
    "      write_file(user_prmpt_path, str(row))\n",
    "      write_file(output_path, str(output))\n",
    "  \n",
    "  return print(\"Stage 2 Complete\")\n",
    "\n",
    "\n",
    "def get_testing_info(wtype, treat, stg, sum=True):  # Just making life easier for getting request file paths & data in sub-tests\n",
    "  extension = f'{treat}_{wtype}'\n",
    "  if sum == True:\n",
    "    df_name = f'RAsum_{extension}.csv'\n",
    "    test_df = pd.read_csv(f'test_data/{df_name}')\n",
    "  else:\n",
    "    df_name = f'{extension}.csv'\n",
    "    test_df = pd.read_csv(f'test_data/{df_name}')\n",
    "  \n",
    "  if stg == 2:\n",
    "    sys_path = f'code/prompts/{wtype}/{treat}/sys_2_{extension}.md'\n",
    "    return sys_path, test_df\n",
    "  else:\n",
    "    sys_path = f'code/prompts/{wtype}/{treat}/sys_{str(stg)}_{extension}.md'\n",
    "    user_path = f'code/prompts/{wtype}/{treat}/user_{str(stg)}_{extension}.md'\n",
    "    return sys_path, user_path, df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## Requests ##\n",
    "##############\n",
    "\n",
    "## Preliminaries\n",
    "test = 'test_10'\n",
    "window_type = 'ucoop'\n",
    "treatment = 'noise'\n",
    "summary_data = True\n",
    "ucoop_test_data = pd.read_csv(f'test_data/RAsum_{treatment}_ucoop.csv')\n",
    "udef_test_data = pd.read_csv(f'test_data/RAsum_{treatment}_udef.csv')\n",
    "ucoop_test_data = ucoop_test_data[:20]\n",
    "ucoop_test_data['window_number'] = ucoop_test_data['window_number'].astype(int)\n",
    "udef_test_data = udef_test_data[:20]\n",
    "udef_test_data['window_number'] = udef_test_data['window_number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-test 10055 complete\n"
     ]
    }
   ],
   "source": [
    "## Sub-test\n",
    "sys, user, df_name = get_testing_info(window_type, treatment, 1, summary_data)\n",
    "test_GPT(sys, user, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Complete\n"
     ]
    }
   ],
   "source": [
    "## Stage 1\n",
    "stage_1_output(treatment, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Refinement Complete\n"
     ]
    }
   ],
   "source": [
    "## Stage 1 Refinement\n",
    "stage_1r_output(treatment, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 Complete\n"
     ]
    }
   ],
   "source": [
    "## Stage 2\n",
    "stage_2_output(treatment, test, ucoop_test_data, udef_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
